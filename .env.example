# ──────────────────────────────────────────────────────────────────────────────
# SentinelAI Environment Variables
# Copy this file to .env and fill in real values. NEVER commit .env to git.
# ──────────────────────────────────────────────────────────────────────────────

# ── GitHub App Credentials (required) ─────────────────────────────────────────
APP_ID=your_app_id_here
WEBHOOK_SECRET=your_webhook_secret_here

# Paste the full PEM content on a single line, with literal \n for newlines.
# Example: -----BEGIN RSA PRIVATE KEY-----\nMIIE...\n-----END RSA PRIVATE KEY-----
PRIVATE_KEY=your_private_key_here

# ── AI Provider (required) ─────────────────────────────────────────────────────
# Choose either "gemini" or "openai"
AI_PROVIDER=gemini

# Gemini API key (required if AI_PROVIDER=gemini)
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API key (required if AI_PROVIDER=openai)
# OPENAI_API_KEY=your_openai_api_key_here

# ── Optional Overrides ─────────────────────────────────────────────────────────
# Default: gemini-2.0-flash (Gemini) | gpt-4o (OpenAI)
# AI_MODEL=gemini-1.5-pro

# Maximum characters of diff to send to the LLM (default: 30000)
# MAX_DIFF_CHARS=30000

# Port for the local Probot server (default: 3000)
# PORT=3000
